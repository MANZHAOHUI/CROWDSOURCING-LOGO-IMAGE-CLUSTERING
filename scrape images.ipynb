{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtCore import *\n",
    "#from PyQt5.QtWebKit import *\n",
    "from lxml import html\n",
    "import time\n",
    "import random\n",
    "#import cPickle as pickle\n",
    "import bs4\n",
    "import urllib\n",
    "import urllib.request\n",
    "import csv\n",
    "import os\n",
    "#from PyQt5.QtWebEngineWidgets import QWebEngineView\n",
    "from PyQt5.QtWebEngineWidgets import QWebEnginePage, QWebEngineView\n",
    "import pickle\n",
    "from PyQt5.QtWidgets import QApplication\n",
    "from PyQt5.QtCore import QUrl\n",
    "\n",
    "def write_row_to_csv(row):\n",
    "    with open('d:\\data\\data.csv','w',encoding='utf8',newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)\n",
    "\n",
    "#Take this class for granted.Just use result of rendering.\n",
    "# class Render(QWebEngineView):\n",
    "#     def __init__(self, url):\n",
    "#         if QApplication.instance():\n",
    "#             self.app = QApplication.instance()\n",
    "#         else:\n",
    "#             self.app = QApplication(sys.argv)\n",
    "#         QWebEngineView.__init__(self)\n",
    "#         self.loadFinished.connect(self._loadFinished)\n",
    "#         self.load(QUrl(url))\n",
    "#         self.app.exec_()\n",
    "\n",
    "#     def _loadFinished(self, result):\n",
    "#         #self.frame = self.mainFrame()\n",
    "#         self.page().toHtml(self.callable)\n",
    "#         self.app.quit()\n",
    "\n",
    "class Render(QWebEngineView):               # 子类Render继承父类QWebEngineView\n",
    "    def __init__(self, url):\n",
    "        self.html = ''\n",
    "        self.app = QApplication(sys.argv)\n",
    "        QWebEngineView.__init__(self)       # 子类构造函数继承父类，这种写法python2和3通用，还可以是super().__init__()\n",
    "        self.loadFinished.connect(self._loadFinished)\n",
    "        self.load(QUrl(url))\n",
    "        self.app.exec_()\n",
    "\n",
    "    def _loadFinished(self):\n",
    "        self.page().toHtml(self.callable)\n",
    "\n",
    "    def callable(self, data):\n",
    "        self.html = data\n",
    "        self.app.quit()\n",
    "\n",
    "base_url = 'https://www.designhill.com/logo-design/contest/agriculture-logo-design-required-141296'\n",
    "page_numbers = [''] + ['?page=' + str(x) for x in range(5)]\n",
    "contest_links = []\n",
    "gather_contest_links = False\n",
    "\n",
    "if gather_contest_links:\n",
    "    for page in page_numbers:\n",
    "        url = base_url + page\n",
    "        r = Render(url)\n",
    "        result = r.html\n",
    "        #This step is important.Converting QString to Ascii for lxml to process\n",
    "        links = html.fromstring(str(result.encode('utf-8'))).find_class('allEntriesLink')\n",
    "        for link in links:\n",
    "            for i, a in enumerate(html.iterlinks(link)):\n",
    "                if i == 0:\n",
    "                    #print(a[2])\n",
    "                    contest_links.append(a[2])\n",
    "\n",
    "        time.sleep(10 + (random.random() * 10))\n",
    "\n",
    "    pickle.dump(contest_links, open(\"d:\\\\contest_links.pickle\", \"wb\"))\n",
    "\n",
    "if not gather_contest_links:\n",
    "    contest_links = pickle.load(open(\"d:\\\\contest_links.pickle\", \"rb\"))\n",
    "\n",
    "if \"completed_links.pickle\" in os.listdir('.'):\n",
    "    completed_links = pickle.load(open(\"d:\\\\completed_links.pickle\", \"rb\"))\n",
    "else:\n",
    "    completed_links = []\n",
    "\n",
    "for link in contest_links:\n",
    "    if link in completed_links:\n",
    "        continue\n",
    "    #print(link)\n",
    "    r = Render(link)\n",
    "    result = r.html\n",
    "    html_string = str(result.encode('utf-8'))\n",
    "    soup = bs4.BeautifulSoup(html_string, 'html.parser')\n",
    "    entries = soup.find_all('div', class_='entries-box')\n",
    "    name = link.split('/')[-1]\n",
    "    for entry in entries:\n",
    "        ribbons = entry.find_all('div', class_='ribbon_text')\n",
    "        if len(ribbons) > 0:\n",
    "            if 'winner' in ribbons[0].text.lower():\n",
    "                winner = True\n",
    "            else:\n",
    "                winner = False\n",
    "        else:\n",
    "            winner = False\n",
    "\n",
    "        img_link = entry.find_all('div', class_='personalDesImg')\n",
    "        if len(img_link) > 0:\n",
    "            img_link = img_link[0].find_all('img')[0]['src']\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        stars = int(entry.find_all('span', class_='star-rating')[0]['data-rating'])\n",
    "        author = entry.find_all('span', class_='author-name')[0].string\n",
    "        urllib.request.urlretrieve(img_link, 'C:\\\\pics/' + img_link.split('/')[-1].split('?')[0])\n",
    "        number = entry.find_all('div', class_='color-code')[0].string.strip('#')\n",
    "        write_row_to_csv([name, number, author, stars, img_link.split('/')[-1].split('?')[0]])\n",
    "        time.sleep(5 + (random.random() * 5))\n",
    "    time.sleep(10 + (random.random() * 10))\n",
    "    completed_links.append(link)\n",
    "    pickle.dump(completed_links, open(\"d:\\\\completed_links.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
